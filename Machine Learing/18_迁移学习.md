#### 18.迁移学习（Transfer Learning）

* ##### 18.1 概述

  * 背景

    * 有与所考虑的任务不直接相关的数据
    * 相同的域，不同的任务
    * 不同的域，相同的任务

  * 框图

    ![avatar](./images/u181_Transfer_Learning.png)

  * Model Fine-tuning

    * 结构

      ![avatar](./images/u181_Model_Fine_tuning.png)

    * 方法

      * Conservative Training

        ![avatar](./images/u181_Conservative_Training.png)

      * Layer Transfer

        ![avatar](./images/u181_Layer_Transfer_1.png)

        ![avatar](./images/u181_Layer_Transfer_2.png)

        ![avatar](./images/u181_Layer_Transfer_3.png)

  * Multitask Learning
  
    * 结构
    
      ![avatar](./images/u181_Multitask_Learning_1.png)
    
    * 应用
    
      * Multilingual Speech Recognition
    
        ![avatar](./images/u181_Multitask_Learning_2.png)
    
      * Progressive Neural Network
    
        ![avatar](./images/u181_Multitask_Learning_3.png)

  * Domain-adversarial training

    * Task description

      ![avatar](./images/u181_Task_description.png)

    * Domain-adversarial training

      ![avatar](./images/u181_Domain_adversarial_training_1.png)

      ![avatar](./images/u181_Domain_adversarial_training_2.png)

  * Zero-shot learning

    * 结构

      ![avatar](./images/u181_Zero_shot_learning_1.png)

    * 用属性表示每个类
  
      * Training : 丰富的 attributes 对于一一映射
      * Testing : 找到最相似的 attributes 类，丰富的 attributes 对于一一映射

    * 举例

      ![avatar](./images/u181_Zero_shot_learning_2.png)

      ![avatar](./images/u181_Zero_shot_learning_3.png)
  
      ![avatar](./images/u181_Zero_shot_learning_4.png)
      
      ![avatar](./images/u181_Zero_shot_learning_5.png)

---

* **18.2 域适应（Domain Adaptation）**

  * 概述

    * Domain Adaptation Foundations

      * Transfer Learning v.s. Domain Adaptation

        ![avatar](./images/u182_Transfer_Learning_vs_Domain_Adaptation.png)

      * 背景
        * Task 针对 target domain，但在 training 时 target doamin 没有（或是很少）label
        * Source Domain 是 fully labelled
      * DA Settings
        * Homogeneous DA
        * Eg, Source / Target are both images

    * Domain Adaptation Methods Overview

      * Discrepancy-based methods

        * 图解

          ![avatar](./images/u182_Discrepancy_based.png)

        * 方法

          * Deep Domain Confusion (MMD)

            ![avatar](./images/u182_MMD.png)

          * Deep Adaptation Networks

            ![avatar](./images/u182_Deep_Adaptation_Networks.png)

          * CORAL, CMD

            * CORAL : use 2nd order meoments

              ![avatar](./images/u182_CORAL.png)

            * CMD : use even higher moments

              ![avatar](./images/u182_CMD.png)

      * Adversarial-based methods

        * 图解

          ![avatar](./images/u182_Adversarial_based.png)

        * 方法

          * Simultaneous Deep Transfer Across Domains and Tasks

            ![avatar](./images/u182_Domains_classifier.png)

          * Domain Adversarial Training of Neural Networks (quick recap)

            * Input sampled from target domain

            * Class label: Unlabelled, domain label 0

              ![avatar](./images/u182_DANN.png)

          * PixelDA

            ![avatar](./images/u182_PixelDA.png)

      * Reconstruction-based methods

        * 图解

          ![avatar](./images/u182_Reconstruction_based.png)

        * Deep Separation Networks

          * 亮点 : 特性解缠，共享/独占特性

            ![avatar](./images/u182_Deep_Separation_Networks.png)

  * 应用

    * Image to Image Translation

      * UNIT (Unsupervised Image-to-Image Translation Networks)

        * Two distincu domains

        * Unpaired tarining data

        * Share the same latent space

        * Domain Invariant feature

          

        * Weight Sharing in high-dimensional space

        * Learning share latent space

          

        * VAE Loss

        * GAN Loss

        * Cycle Consistency Loss

          ![avatar](./images/u182_UNIT.png)

      * Multi-model Image Translation

        * Multimodal Unsupervised Image-to-Image Translation (MUNIT)

          * Two distinct domains (Diverse image)

          * Unpaired training data

          * Disentangle features into content and style features

            

          * Bidirectional  reconstruction loss

          * Adversarial loss

        * Diverse Image-to-Image Translation via Disentangled Representations (DRIT)

    * Semantic Segmentation

      * Learning to Adapt Structured Output Space for Semantic Segmentation (AdaptSegNet)

        * Two distinct domains (Syntheic vs Real)

        * Only source domain has labeled data

        * Structured output share many similarities

          

        * Segmentation Loss

        * Adversarial Loss

          ![avatar](./images/u182_AdaptSegNet.png)

      * Unsupervised Domain Adaptation for Semantic Segmentation via Class-Balanced Self-Training (CBST)

        * Two distinct domains  (Syntheic vs Real)

        * Only source domain has  labeled data

        * Iterative self-training  (pseudo label)

          

        * Self-Training Scheme

        * Each class has unique threshold to  determine its pseudo labels

        * Incorporate with spatial priors

          

        * Some classes are easy to optimize, some are not

        * k should be dependent on class

        * Different classes have different prior distributions

        * Softmax output multiplies spatial prior (0~1)

          

        * Self-Training

          ![avatar](./images/u182_Self_Training_1.png)

          ![avatar](./images/u182_Self_Training_2.png)

    * Person Re-ID

      * Image-image domain adaptation with preserved self-similarity and domain-dissimilarity for person re-identification (SPGAN)

        * Two distinct domains (Market vs Duke)

        * Only source domain has labeled data

        * Self-Similarity and Domain-Dissimilarity

          ![avatar](./images/u182_SPGAN.png)

      * Invariance matters: Exemplar memory for domain adaptive person re-identification (ECN)

        * Two distinct domains (Market vs Duke)

        * Only source domain has labeled data

        * Intra-domain variation (Three kinds of invariance)

          ![avatar](./images/u182_ECN.png)

